{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfmxHJIA4Aca3Qn/CBws1J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WaryFriend456/NLP/blob/main/nlplab_p3_22BD1A660W_12_03_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iU569Y7BYbe",
        "outputId": "6f57e434-b60a-4798-99fe-c32fdddc20d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wikipedia-api in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from wikipedia-api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install wikipedia-api"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnlMoHPWCWCN",
        "outputId": "3fa61b28-32f6-4320-a65d-655519334708"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import wikipediaapi\n",
        "import spacy\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "OMUZRN08CV_u"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wikipedia_text(page_title):\n",
        "    wiki_wiki = wikipediaapi.Wikipedia(user_agent=\"MyNLPProjectP3/1.0\", language=\"en\")\n",
        "    page = wiki_wiki.page(page_title)\n",
        "    return page.summary if page.exists() else \"\"\n",
        "\n",
        "text = get_wikipedia_text(\"Keshav_Memorial_Institute_of_Technology\")\n",
        "print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bxBWPYMCV9b",
        "outputId": "f30907e4-9f40-4f37-d898-4b44895ec5bf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keshav Memorial Institute of Technology is a private engineering college in Hyderabad in Telangana, India.\n",
            "It offers B.Tech degrees in computer science and engineering, artificial intelligence and machine learning, data science, and information technology.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(text)"
      ],
      "metadata": {
        "id": "LYLwDtjUDbSv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "start_stem = time.time()\n",
        "stemmed_words = [stemmer.stem(word) for word in tokens]\n",
        "end_stem = time.time()\n",
        "\n",
        "# Step 3: Apply Lemmatization\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "start_lem = time.time()\n",
        "doc = nlp(\" \".join(tokens))\n",
        "lemmatized_words = [token.lemma_ for token in doc]\n",
        "end_lem = time.time()\n",
        "\n",
        "\n",
        "print(\"Original Text Sample:\", tokens[:10])\n",
        "print(\"Stemmed Words:\", stemmed_words[:10])\n",
        "print(\"Lemmatized Words:\", lemmatized_words[:10])\n",
        "\n",
        "\n",
        "print(\"\\nPerformance Analysis:\")\n",
        "print(f\"Stemming Execution Time: {end_stem - start_stem:.5f} seconds\")\n",
        "print(f\"Lemmatization Execution Time: {end_lem - start_lem:.5f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVq8vgR4CV7W",
        "outputId": "55db081b-a08d-4789-fb90-1f353184957f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text Sample: ['Keshav', 'Memorial', 'Institute', 'of', 'Technology', 'is', 'a', 'private', 'engineering', 'college']\n",
            "Stemmed Words: ['keshav', 'memori', 'institut', 'of', 'technolog', 'is', 'a', 'privat', 'engin', 'colleg']\n",
            "Lemmatized Words: ['Keshav', 'Memorial', 'Institute', 'of', 'Technology', 'be', 'a', 'private', 'engineering', 'college']\n",
            "\n",
            "Performance Analysis:\n",
            "Stemming Execution Time: 0.00080 seconds\n",
            "Lemmatization Execution Time: 0.01334 seconds\n"
          ]
        }
      ]
    }
  ]
}